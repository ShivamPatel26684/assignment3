{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7ef20f0-722f-4240-8a79-437d4a3b8832",
      "metadata": {
        "id": "f7ef20f0-722f-4240-8a79-437d4a3b8832"
      },
      "source": [
        "## Assignment 3: $k$ Nearest Neighbor and $k$ Means Clustering\n",
        "\n",
        "## **Do three questions.**\n",
        "\n",
        "`! git clone https://www.github.com/DS3001/assignment3`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0f34497-2d71-4705-ac63-c0532e545022",
      "metadata": {
        "id": "d0f34497-2d71-4705-ac63-c0532e545022"
      },
      "source": [
        "**Q1.** This question is a case study for $k$ nearest neighbor. The target variable `y` is `Purchase` and the features of interest are `Age` and `AnnualSalary`.\n",
        "\n",
        "1. Load the `./data/car_data.csv` data. Look at the head and dimensions of the data.\n",
        "2. Summarize the variables (`User.ID`, `Gender`, `Age`, `AnnualSalary`, `Purchase`). Are there any missings to clean? Convert the `Gender` categorical variable into a dummy variable that takes the value 0 for male and 1 for female. Create a matrix $X$ of predictors including `Age` and `AnnualSalary`, and an outcome $y$ equaling `Purchase`.\n",
        "3. MaxMin-normalize `Age` and `AnnualSalary` in `X`.\n",
        "4. Split the sample into a ~80% training dataset and a ~20% testing dataset.\n",
        "5. Treat this as a classification problem: The model is supposed to predict 0 or 1 for each customer, classifying them as a purchaser or non-purchaser. Use sklearn to determine the optimal number of neighbors $k$ to use.\n",
        "6. Run the model for the optimal number of neighbors on the testing data. Cross tabulate the predicted outcomes against the actual outcomes; this is called a **confusion matrix**. How often does the model predict a sale when one fails to occur? How often does the model predict no sale when one does occur? Overall, does it provide accurate predictions?\n",
        "7. Now, compute confusion matrices separately for men and women, as in part 6. Does the model make more accurate predictions for one sex or the other? Explain. (Performance of algorithms on population subgroups is a growing topic in data science.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "def pn(x):\n",
        "  print(x,'\\n')\n",
        "  return"
      ],
      "metadata": {
        "id": "lPqOM2lZVDw4"
      },
      "id": "lPqOM2lZVDw4",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1.1\n",
        "df = pd.read_csv('/content/car_data.csv')\n",
        "pn(df.head())\n",
        "pn(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F71f_z6LV8wE",
        "outputId": "1744db5c-b474-4d21-d586-f817aafa9035"
      },
      "id": "F71f_z6LV8wE",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   User ID Gender  Age  AnnualSalary  Purchased\n",
            "0      385   Male   35         20000          0\n",
            "1      681   Male   40         43500          0\n",
            "2      353   Male   49         74000          0\n",
            "3      895   Male   40        107500          1\n",
            "4      661   Male   25         79000          0 \n",
            "\n",
            "(1000, 5) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.2.1\n",
        "pn(df[['User ID', 'Gender', 'Age', 'AnnualSalary', 'Purchased']].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOf_HhHaWtv9",
        "outputId": "4fa4e09c-6586-41b0-f0b9-f18cec5cfccc"
      },
      "id": "iOf_HhHaWtv9",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           User ID          Age   AnnualSalary    Purchased\n",
            "count  1000.000000  1000.000000    1000.000000  1000.000000\n",
            "mean    500.500000    40.106000   72689.000000     0.402000\n",
            "std     288.819436    10.707073   34488.341867     0.490547\n",
            "min       1.000000    18.000000   15000.000000     0.000000\n",
            "25%     250.750000    32.000000   46375.000000     0.000000\n",
            "50%     500.500000    40.000000   72000.000000     0.000000\n",
            "75%     750.250000    48.000000   90000.000000     1.000000\n",
            "max    1000.000000    63.000000  152500.000000     1.000000 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.2.2\n",
        "checkNull = df.isnull().sum()\n",
        "pn(checkNull)\n",
        "if (checkNull == 0).all():\n",
        "  pn(\"No Null Values\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvHj_OXqYB4d",
        "outputId": "b78964a2-3a26-4429-9d7d-47203217d028"
      },
      "id": "jvHj_OXqYB4d",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User ID         0\n",
            "Gender          0\n",
            "Age             0\n",
            "AnnualSalary    0\n",
            "Purchased       0\n",
            "dtype: int64 \n",
            "\n",
            "No Null Values \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.2.3\n",
        "df['numGender'] = df['Gender'].replace(['Male','Female'],[0,1])\n",
        "pn(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94Ze_n-iYO3z",
        "outputId": "b1fcc590-fbdf-4735-9778-632e2753ba53"
      },
      "id": "94Ze_n-iYO3z",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     User ID  Gender  Age  AnnualSalary  Purchased  numGender\n",
            "0        385    Male   35         20000          0          0\n",
            "1        681    Male   40         43500          0          0\n",
            "2        353    Male   49         74000          0          0\n",
            "3        895    Male   40        107500          1          0\n",
            "4        661    Male   25         79000          0          0\n",
            "..       ...     ...  ...           ...        ...        ...\n",
            "995      863    Male   38         59000          0          0\n",
            "996      800  Female   47         23500          0          1\n",
            "997      407  Female   28        138500          1          1\n",
            "998      299  Female   48        134000          1          1\n",
            "999      687  Female   44         73500          0          1\n",
            "\n",
            "[1000 rows x 6 columns] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.2.4\n",
        "X = df.loc[:,['Age','AnnualSalary']]\n",
        "y = df['Purchased']\n",
        "pn(X)\n",
        "pn(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vf6RjhsZkL2",
        "outputId": "2e04e8a6-893f-4f7e-d81f-585c4e6e0438"
      },
      "id": "1Vf6RjhsZkL2",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Age  AnnualSalary\n",
            "0     35         20000\n",
            "1     40         43500\n",
            "2     49         74000\n",
            "3     40        107500\n",
            "4     25         79000\n",
            "..   ...           ...\n",
            "995   38         59000\n",
            "996   47         23500\n",
            "997   28        138500\n",
            "998   48        134000\n",
            "999   44         73500\n",
            "\n",
            "[1000 rows x 2 columns] \n",
            "\n",
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      1\n",
            "4      0\n",
            "      ..\n",
            "995    0\n",
            "996    0\n",
            "997    1\n",
            "998    1\n",
            "999    0\n",
            "Name: Purchased, Length: 1000, dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.3\n",
        "def maxmin(z):\n",
        "    z = (z-min(z))/(max(z)-min(z))\n",
        "    return(z)\n",
        "\n",
        "X = X.apply(maxmin)\n",
        "pn(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VXB7Wj2amj_",
        "outputId": "a44f8cb0-ee9b-4b6a-df3b-907788102013"
      },
      "id": "4VXB7Wj2amj_",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Age  AnnualSalary\n",
            "0    0.377778      0.036364\n",
            "1    0.488889      0.207273\n",
            "2    0.688889      0.429091\n",
            "3    0.488889      0.672727\n",
            "4    0.155556      0.465455\n",
            "..        ...           ...\n",
            "995  0.444444      0.320000\n",
            "996  0.644444      0.061818\n",
            "997  0.222222      0.898182\n",
            "998  0.666667      0.865455\n",
            "999  0.577778      0.425455\n",
            "\n",
            "[1000 rows x 2 columns] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.4\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state=100)"
      ],
      "metadata": {
        "id": "p1hsMFyobKtj"
      },
      "id": "p1hsMFyobKtj",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Credit to Monkhaus from Youtube: \"PYTHON KNN CLASSIFIER | How to find the optimal value of k without over-fitting - PART 7\"\n",
        "#1.5\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from matplotlib import pyplot as plt\n",
        "k_bar = 70\n",
        "k_values = [i for i in range(1, k_bar + 1,2)]\n",
        "k_acc_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "  knn = KNeighborsClassifier(n_neighbors = k, n_jobs = -1)\n",
        "  cv_scores = cross_val_score(knn, X_train, y_train, cv = 5, scoring = 'accuracy')\n",
        "  k_acc_scores.append(cv_scores.mean())\n",
        "\n",
        "max_k_acc_score = max(k_acc_scores)\n",
        "max_k_acc_score_index = k_acc_scores.index(max_k_acc_score)\n",
        "optimal_k = k_values[max_k_acc_score_index]\n",
        "pn(\"Optimal K value: \"+ str(optimal_k))\n",
        "\n",
        "plt.plot(k_values, k_acc_scores)\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"acc\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "Qp2RidNdb15R",
        "outputId": "116b2947-9abf-491b-b4ff-7b8914dbff30"
      },
      "id": "Qp2RidNdb15R",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal K value: 5 \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.6\n",
        "model = KNeighborsClassifier(n_neighbors = optimal_k)\n",
        "classifer_model = model.fit(X_train, y_train)\n",
        "y_pred = classifer_model.predict(X_test)\n",
        "confusion_matrix = pd.crosstab(y_test, y_pred)\n",
        "confusion_matrix = confusion_matrix.rename_axis('y_pred', axis=1)\n",
        "confusion_matrix = confusion_matrix.rename_axis('y_test', axis=0)\n",
        "pn(confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnijTrB_i9Fl",
        "outputId": "26d8160d-2cb1-4f87-ce92-e9bada8d43c8"
      },
      "id": "AnijTrB_i9Fl",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred    0   1\n",
            "y_test         \n",
            "0       102  17\n",
            "1         3  78 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model predicts a sale when one fails to occur 17 times. The model predicts no sale when one does occur 3 times. Overall there was 200 data points and 20 out of 200 were incorrectly predicted which means there was 10% error. This means the model is accurate up to 90%. Therefore, the model does provide accurate predictions, however, we would have to account for at least 10% error."
      ],
      "metadata": {
        "id": "5FbNFFTtr2mq"
      },
      "id": "5FbNFFTtr2mq"
    },
    {
      "cell_type": "code",
      "source": [
        "#1.7.1 (male)\n",
        "male_data = df[df['numGender']==0]\n",
        "X = male_data.loc[:,[\"Age\",\"AnnualSalary\"]]\n",
        "y = male_data[\"Purchased\"]\n",
        "\n",
        "X = X.apply(maxmin)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state=100)\n",
        "k_bar = 70\n",
        "k_values = [i for i in range(1, k_bar + 1,2)]\n",
        "k_acc_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "  knn = KNeighborsClassifier(n_neighbors = k, n_jobs = -1)\n",
        "  cv_scores = cross_val_score(knn, X_train, y_train, cv = 5, scoring = 'accuracy')\n",
        "  k_acc_scores.append(cv_scores.mean())\n",
        "\n",
        "max_k_acc_score = max(k_acc_scores)\n",
        "max_k_acc_score_index = k_acc_scores.index(max_k_acc_score)\n",
        "optimal_k = k_values[max_k_acc_score_index]\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors = optimal_k)\n",
        "classifer_model = model.fit(X_train, y_train)\n",
        "y_pred = classifer_model.predict(X_test)\n",
        "confusion_matrix = pd.crosstab(y_test, y_pred)\n",
        "confusion_matrix = confusion_matrix.rename_axis('y_pred', axis=1)\n",
        "confusion_matrix = confusion_matrix.rename_axis('y_test', axis=0)\n",
        "pn(confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go9NSCXqwN8_",
        "outputId": "a229e4e3-cefb-47fc-e20e-04ed356b4af7"
      },
      "id": "Go9NSCXqwN8_",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred   0   1\n",
            "y_test        \n",
            "0       59   3\n",
            "1        3  32 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.7.2 (female)\n",
        "female_data = df[df['numGender']==1]\n",
        "X = female_data.loc[:,[\"Age\",\"AnnualSalary\"]]\n",
        "y = female_data[\"Purchased\"]\n",
        "\n",
        "X = X.apply(maxmin)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state=100)\n",
        "k_bar = 70\n",
        "k_values = [i for i in range(1, k_bar + 1,2)]\n",
        "k_acc_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "  knn = KNeighborsClassifier(n_neighbors = k, n_jobs = -1)\n",
        "  cv_scores = cross_val_score(knn, X_train, y_train, cv = 5, scoring = 'accuracy')\n",
        "  k_acc_scores.append(cv_scores.mean())\n",
        "\n",
        "max_k_acc_score = max(k_acc_scores)\n",
        "max_k_acc_score_index = k_acc_scores.index(max_k_acc_score)\n",
        "optimal_k = k_values[max_k_acc_score_index]\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors = optimal_k)\n",
        "classifer_model = model.fit(X_train, y_train)\n",
        "y_pred = classifer_model.predict(X_test)\n",
        "confusion_matrix = pd.crosstab(y_test, y_pred)\n",
        "confusion_matrix = confusion_matrix.rename_axis('y_pred', axis=1)\n",
        "confusion_matrix = confusion_matrix.rename_axis('y_test', axis=0)\n",
        "pn(confusion_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6vgzsw5zUpn",
        "outputId": "b6724725-ac6f-4676-a202-8c72f86690b5"
      },
      "id": "G6vgzsw5zUpn",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred   0   1\n",
            "y_test        \n",
            "0       56   8\n",
            "1        5  35 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model make more accurate predictions for males than for females. Looking at the confusion matrices, for the male confusion matrix, the model  predicted 6 out of 97 points incorrectly which results in 6.12% error while for the female confusion matrix, the model predicted 13 out of 104 points incorrectly which results in 12.5% error. Therefore, the model had almost double the error for females than for males."
      ],
      "metadata": {
        "id": "TEjqghHqzrsa"
      },
      "id": "TEjqghHqzrsa"
    },
    {
      "cell_type": "markdown",
      "id": "71c9e0b8-17f5-4ff9-9c76-2034bffe8d5c",
      "metadata": {
        "id": "71c9e0b8-17f5-4ff9-9c76-2034bffe8d5c"
      },
      "source": [
        "**Q2.** This question is a case study for $k$ nearest neighbor The target variable `y` is `price` and the features are `year` and `mileage`.\n",
        "\n",
        "1. Load the `./data/USA_cars_datasets.csv`. Keep the following variables and drop the rest: `price`, `year`, `mileage`. Are there any `NA`'s to handle? Look at the head and dimensions of the data.\n",
        "2. Maxmin normalize `year` and `mileage`.\n",
        "3. Split the sample into ~80% for training and ~20% for evaluation.\n",
        "4. Use the $k$NN algorithm for regression and the training data to predict `price` using `year` and `mileage` for the test set for $k=3,10,25,50,100,300$. For each value of $k$, compute the Sum of Squared Error and make a scatterplot showing the test value plotted against the predicted value. What patterns do you notice as you increase $k$?\n",
        "5. Determine the optimal $k$ for these data.\n",
        "6. Describe what happened in the plots of predicted versus actual prices as $k$ varied, taking your answer into part 6 into account. (Hint: Use the words \"underfitting\" and \"overfitting\".)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "010b57f7-bf4f-4494-b54c-49c4f3ae3ab9",
      "metadata": {
        "id": "010b57f7-bf4f-4494-b54c-49c4f3ae3ab9"
      },
      "source": [
        "**Q3.** This question is a case study for $k$ nearest neighbor, particularly variable selection. The data for the question include (summaries reproduced here directly from the codebook):\n",
        "\n",
        "- age: age of the patient (years)\n",
        "- anaemia: decrease of red blood cells or hemoglobin (boolean)\n",
        "- high blood pressure: if the patient has hypertension (boolean)\n",
        "- creatinine phosphokinase (CPK): level of the CPK enzyme in the blood (mcg/L)\n",
        "- diabetes: if the patient has diabetes (boolean)\n",
        "- ejection fraction: percentage of blood leaving the heart at each contraction (percentage)\n",
        "- platelets: platelets in the blood (kiloplatelets/mL)\n",
        "- sex: woman or man (binary)\n",
        "- serum creatinine: level of serum creatinine in the blood (mg/dL)\n",
        "- serum sodium: level of serum sodium in the blood (mEq/L)\n",
        "- smoking: if the patient smokes or not (boolean)\n",
        "- time: follow-up period (days)\n",
        "- death event: if the patient deceased during the follow-up period (boolean)\n",
        "\n",
        "1. Load the `./data/heart_failure_clinical_records_dataset.csv`. Are there any `NA`'s to handle? use `.drop()` to remove `time` from the dataframe.\n",
        "2. Make a correlation matrix. What variables are strongly associated with a death event?\n",
        "3. For the dummy variables `anaemia`, `diabetes`, `high_blood_pressure`, `sex`, and `smoking`, compute a summary table of `DEATH_EVENT` grouped by the variable. For which variables does a higher proportion of the population die when the variable takes the value 1 rather than 0?\n",
        "4. On the basis of your answers from 2 and 3, build a matrix $X$ of the variables you think are most predictive of a death, and a variable $y$ equal to `DEATH_EVENT`.\n",
        "5. Maxmin normalize all of the variables in `X`.\n",
        "6. Split the sample into ~80% for training and ~20% for evaluation. (Try to use the same train/test split for the whole question, so that you're comparing apples to apples in the questions below.).\n",
        "7. Determine the optimal number of neighbors for a $k$NN regression for the variables you selected.\n",
        "8. OK, do steps 5 through 7 again, but use all of the variables (except `time`). Which model has a lower Sum of Squared Error? Which would you prefer to use in practice, if you had to predict `DEATH_EVENT`s? If you play with the selection of variables, how much does the SSE change for your fitted model on the test data? Are more variables better, in this case? Explain your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d457e190-d273-455f-b94f-62916cb5af1c",
      "metadata": {
        "id": "d457e190-d273-455f-b94f-62916cb5af1c"
      },
      "source": [
        "**Q4.** Let's do some very basic computer vision. We're going to import the MNIST handwritten digits data and $k$NN to predict values (i.e. \"see/read\").\n",
        "\n",
        "1. To load the data, run the following code in a chunk:\n",
        "```\n",
        "from keras.datasets import mnist\n",
        "df = mnist.load_data('minst.db')\n",
        "train,test = df\n",
        "X_train, y_train = train\n",
        "X_test, y_test = test\n",
        "```\n",
        "The `y_test` and `y_train` vectors, for each index `i`, tell you want number is written in the corresponding index in `X_train[i]` and `X_test[i]`. The value of `X_train[i]` and `X_test[i]`, however, is a 28$\\times$28 array whose entries contain values between 0 and 256. Each element of the matrix is essentially a \"pixel\" and the matrix encodes a representation of a number. To visualize this, run the following code to see the first ten numbers:\n",
        "```\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.set_printoptions(edgeitems=30, linewidth=100000)\n",
        "for i in range(5):\n",
        "    print(y_test[i],'\\n') # Print the label\n",
        "    print(X_test[i],'\\n') # Print the matrix of values\n",
        "    plt.contourf(np.rot90(X_test[i].transpose())) # Make a contour plot of the matrix values\n",
        "    plt.show()\n",
        "```\n",
        "OK, those are the data: Labels attached to handwritten digits encoded as a matrix.\n",
        "\n",
        "2. What is the shape of `X_train` and `X_test`? What is the shape of `X_train[i]` and `X_test[i]` for each index `i`? What is the shape of `y_train` and `y_test`?\n",
        "3. Use Numpy's `.reshape()` method to covert the training and testing data from a matrix into an vector of features. So, `X_test[index].reshape((1,784))` will convert the $index$-th element of `X_test` into a $28\\times 28=784$-length row vector of values, rather than a matrix. Turn `X_train` into an $N \\times 784$ matrix $X$ that is suitable for scikit-learn's kNN classifier where $N$ is the number of observations and $784=28*28$ (you could use, for example, a `for` loop).\n",
        "4. Use the reshaped `X_test` and `y_test` data to create a $k$-nearest neighbor classifier of digit. What is the optimal number of neighbors $k$? If you can't determine this, play around with different values of $k$ for your classifier.\n",
        "5. For the optimal number of neighbors, how well does your predictor perform on the test set?\n",
        "6. So, this is how computers \"see.\" They convert an image into a matrix of values, that matrix becomes a vector in a dataset, and then we deploy ML tools on it as if it was any other kind of tabular data. To make sure you follow this, invent a way to represent a color photo in matrix form, and then describe how you could convert it into tabular data. (Hint: RGB color codes provide a method of encoding a numeric value that represents a color.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a83222f-16f1-47a1-bd92-91dd4bd4ab8d",
      "metadata": {
        "id": "9a83222f-16f1-47a1-bd92-91dd4bd4ab8d"
      },
      "source": [
        "**Q5.** This question is a case study for $k$ means clustering.\n",
        "\n",
        "1. Load the `airbnb_hw.csv` data. Clean `Price` along with `Beds`, `Number of Reviews`, and `Review Scores Rating`.\n",
        "2. Maxmin normalize the data and remove any `nan`'s (`KMeans` from `sklearn` doesn't accept `nan` input).\n",
        "3. Use `sklearn`'s `KMeans` module to cluster the data by `Beds`, `Number of Reviews`, and `Review Scores Rating` for `k=6`.\n",
        "4. Use `seaborn`'s `.pairplot()` to make a grid of scatterplots that show how the clustering is carried out in multiple dimensions.\n",
        "5. Use `.groupby` and `.describe` to compute the average price for each cluster. Which clusters have the highest rental prices?\n",
        "6. Use a scree plot to pick the number of clusters and repeat steps 4 and 5."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d765b942-0ddf-4d42-adbf-8b64eeabf4c9",
      "metadata": {
        "id": "d765b942-0ddf-4d42-adbf-8b64eeabf4c9"
      },
      "source": [
        "**Q6.** This is a question about $k$ means clustering. We want to investigate how adjusting the \"noisiness\" of the data impacts the quality of the algorithm and the difficulty of picking $k$.\n",
        "\n",
        "1. Run the code below, which creates four datasets: `df0_125`, `df0_25`, `df0_5`, `df1_0`, and `df2_0`. Each data set is created by increasing the amount of `noise` (standard deviation) around the cluster centers, from `0.125` to `0.25` to `0.5` to `1.0` to `2.0`.\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def createData(noise,N=50):\n",
        "    np.random.seed(100) # Set the seed for replicability\n",
        "    # Generate (x1,x2,g) triples:\n",
        "    X1 = np.array([np.random.normal(1,1,N),np.random.normal(1,1,N)])\n",
        "    X2 = np.array([np.random.normal(3,1,N),np.random.normal(2,1,N)])\n",
        "    X3 = np.array([np.random.normal(5,1,N),np.random.normal(3,1,N)])\n",
        "    # Concatenate into one data frame\n",
        "    gdf1 = pd.DataFrame({'x1':X1[0,:],'x2':X1[1,:],'group':'a'})\n",
        "    gdf2 = pd.DataFrame({'x1':X2[0,:],'x2':X2[1,:],'group':'b'})\n",
        "    gdf3 = pd.DataFrame({'x1':X3[0,:],'x2':X3[1,:],'group':'c'})\n",
        "    df = pd.concat([gdf1,gdf2,gdf3],axis=0)\n",
        "    return df\n",
        "\n",
        "df0_125 = createData(0.125)\n",
        "df0_25 = createData(0.25)\n",
        "df0_5 = createData(0.5)\n",
        "df1_0 = createData(1.0)\n",
        "df2_0 = createData(2.0)\n",
        "```\n",
        "\n",
        "2. Make scatterplots of the $(X1,X2)$ points by group for each of the datasets. As the `noise` goes up from 0.125 to 2.0, what happens to the visual distinctness of the clusters?\n",
        "3. Create a scree plot for each of the datasets. Describe how the level of `noise` affects the scree plot (particularly the presence of a clear \"elbow\") and your ability to definitively select a $k$.\n",
        "4. Explain the intuition of the elbow, using this numerical simulation as an example."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c73207b-3ca0-4fe7-a561-5380f683498e",
      "metadata": {
        "id": "3c73207b-3ca0-4fe7-a561-5380f683498e"
      },
      "source": [
        "**Q7.** We looked at computer vision with $k$NN in a previous question. Can $k$ means clustering correctly group digits, even if we don't know which symbols are which?\n",
        "\n",
        "1. To load the data, run the following code in a chunk:\n",
        "```\n",
        "from keras.datasets import mnist\n",
        "df = mnist.load_data('minst.db')\n",
        "train,test = df\n",
        "X_train, y_train = train\n",
        "X_test, y_test = test\n",
        "```\n",
        "The `y_test` and `y_train` vectors, for each index `i`, tell you want number is written in the corresponding index in `X_train[i]` and `X_test[i]`. The value of `X_train[i]` and `X_test[i]`, however, is a 28$\\times$28 array whose entries contain values between 0 and 256. Each element of the matrix is essentially a \"pixel\" and the matrix encodes a representation of a number. To visualize this, run the following code to see the first ten numbers:\n",
        "```\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.set_printoptions(edgeitems=30, linewidth=100000)\n",
        "for i in range(5):\n",
        "    print(y_test[i],'\\n') # Print the label\n",
        "    print(X_test[i],'\\n') # Print the matrix of values\n",
        "    plt.contourf(np.rot90(X_test[i].transpose())) # Make a contour plot of the matrix values\n",
        "    plt.show()\n",
        "```\n",
        "OK, those are the data: Labels attached to handwritten digits encoded as a matrix.\n",
        "\n",
        "2. What is the shape of `X_train` and `X_test`? What is the shape of `X_train[i]` and `X_test[i]` for each index `i`? What is the shape of `y_train` and `y_test`?\n",
        "3. Use Numpy's `.reshape()` method to covert the training and testing data from a matrix into an vector of features. So, `X_test[index].reshape((1,784))` will convert the $index$-th element of `X_test` into a $28\\times 28=784$-length row vector of values, rather than a matrix. Turn `X_train` into an $N \\times 784$ matrix $X$ that is suitable for scikit-learn's kNN classifier where $N$ is the number of observations and $784=28*28$ (you could use, for example, a `for` loop).\n",
        "4. Use $k$ means clustering on the reshaped `X_test` data with `k=10`.  \n",
        "5. Cross tabulate the cluster assignments with the true labels for the test set values. How good is the correspondence? What proportion of digits are clustered correctly? Which digits are the hardest to distinguish from one another? Can $k$MC recover the latent digits 0 to 9, without even knowing what those digits were?\n",
        "6. If you use a scree plot to determine the number of clusters $k$, does it pick 10 (the true number of digits), or not? If it fails to pick $k=10$, which digits does it tend to combine into the same classification?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}